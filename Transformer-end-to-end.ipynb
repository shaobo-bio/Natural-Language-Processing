{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Transformer-end-to-end.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPA8Hmi5it/AnMvqaneK5/Q"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["A transformer based natural language processing that classifies the review comments"],"metadata":{"id":"OHK7E9BGw7r-"}},{"cell_type":"code","metadata":{"id":"4UWWOOoRREwo","executionInfo":{"status":"ok","timestamp":1639448812360,"user_tz":480,"elapsed":4118,"user":{"displayName":"Shaobo Zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07927447856433166080"}}},"source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras.layers import TextVectorization\n","from dataclasses import dataclass\n","import pandas as pd\n","import numpy as np\n","import glob\n","import re\n","from pprint import pprint"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"t0RzyMyCRvTs","executionInfo":{"status":"ok","timestamp":1639448812509,"user_tz":480,"elapsed":7,"user":{"displayName":"Shaobo Zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07927447856433166080"}}},"source":["@dataclass\n","class Config:\n","  MAX_LEN=256\n","  BATCH_SIZE=32\n","  LR=0.001\n","  VOCAB_SIZE=30000\n","  EMBED_DIM=128\n","  NUM_HEAD=8\n","  FF_DIM=128\n","  NUM_LAYERS=1\n","\n","config=Config"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sZcQG5SzScXz","executionInfo":{"status":"ok","timestamp":1639448824021,"user_tz":480,"elapsed":11518,"user":{"displayName":"Shaobo Zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07927447856433166080"}},"outputId":"28cd6b64-b5cb-443b-c057-74b9a4494020"},"source":["!curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n","!tar -xf aclImdb_v1.tar.gz"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100 80.2M  100 80.2M    0     0  31.1M      0  0:00:02  0:00:02 --:--:-- 31.1M\n"]}]},{"cell_type":"markdown","source":[""],"metadata":{"id":"TCZ1PttRw6zr"}},{"cell_type":"code","metadata":{"id":"6v5q_kyTSsv9","executionInfo":{"status":"ok","timestamp":1639448860687,"user_tz":480,"elapsed":149,"user":{"displayName":"Shaobo Zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07927447856433166080"}}},"source":["def get_text_list_from_files(files):\n","  text_list=[]\n","  for name in files:\n","    with open(name) as f:\n","      for line in f:\n","        text_list.append(line)\n","  return text_list\n","\n","def get_data_from_text_folder(folder_name):\n","  pos_files=glob.glob(\"aclImdb/\"+folder_name+\"/pos/*.txt\")\n","  pos_text=get_text_list_from_files(pos_files)\n","  neg_files=glob.glob(\"aclImdb/\"+folder_name+\"/neg/*.txt\")\n","  neg_text=get_text_list_from_files(neg_files)\n","\n","  df=pd.DataFrame(\n","      {\n","          \"review\":pos_text+neg_text,\n","          \"sentiment\":[0] * len(pos_text)+[1]*len(neg_text)\n","      }\n","  )\n","\n","  df=df.sample(len(df)).reset_index(drop=True)\n","  return df\n","\n"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"c1zuuUvQVoP_","executionInfo":{"status":"ok","timestamp":1639448866756,"user_tz":480,"elapsed":1336,"user":{"displayName":"Shaobo Zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07927447856433166080"}}},"source":["train_df=get_data_from_text_folder(\"train\")"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":143},"id":"5tTRTMplVvOT","executionInfo":{"status":"ok","timestamp":1639448866786,"user_tz":480,"elapsed":35,"user":{"displayName":"Shaobo Zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07927447856433166080"}},"outputId":"1b83c185-a21b-4905-d750-8726737d9424"},"source":["train_df.head(3)"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>review</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>From rainy, dreary late winter England of earl...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Skip Mission: Galactica and watch the original...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>This movie makes Peter an elf in Robin Hood co...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                              review  sentiment\n","0  From rainy, dreary late winter England of earl...          0\n","1  Skip Mission: Galactica and watch the original...          1\n","2  This movie makes Peter an elf in Robin Hood co...          1"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"RhZovkUNV1qN","executionInfo":{"status":"ok","timestamp":1639448870483,"user_tz":480,"elapsed":1343,"user":{"displayName":"Shaobo Zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07927447856433166080"}}},"source":["test_df=get_data_from_text_folder(\"test\")"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"n32-nhVhW4Pq","executionInfo":{"status":"ok","timestamp":1639448870894,"user_tz":480,"elapsed":6,"user":{"displayName":"Shaobo Zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07927447856433166080"}}},"source":["all_data=train_df.append(test_df)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PjXafxazW-Cq","executionInfo":{"status":"ok","timestamp":1639448872898,"user_tz":480,"elapsed":241,"user":{"displayName":"Shaobo Zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07927447856433166080"}},"outputId":"5f213cfd-cfba-4d8f-904b-b99930ff2c29"},"source":["all_data.size"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["100000"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"tiW2s3xJXACx","executionInfo":{"status":"ok","timestamp":1639448875329,"user_tz":480,"elapsed":119,"user":{"displayName":"Shaobo Zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07927447856433166080"}},"outputId":"01d6525d-9a71-4816-8cb1-5b6c089c4950"},"source":["re.escape(\"!#$%&'()*+,-./:;<=>?@\\^_`{|}~\")"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"!\\\\#\\\\$%\\\\&'\\\\(\\\\)\\\\*\\\\+,\\\\-\\\\./:;<=>\\\\?@\\\\\\\\\\\\^_`\\\\{\\\\|\\\\}\\\\~\""]},"metadata":{},"execution_count":10}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CxRhx7mFYwwJ","executionInfo":{"status":"ok","timestamp":1639448878450,"user_tz":480,"elapsed":131,"user":{"displayName":"Shaobo Zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07927447856433166080"}},"outputId":"366b14f9-31e1-4153-8035-abf4cf510199"},"source":["len([\"[MASK]\"])"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"50GtE2HsYzzp","executionInfo":{"status":"ok","timestamp":1639448879427,"user_tz":480,"elapsed":162,"user":{"displayName":"Shaobo Zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07927447856433166080"}}},"source":["def custom_standardization(input_data):\n","  lowercase=tf.strings.lower(input_data)\n","  stripped_html=tf.strings.regex_replace(lowercase,\"<br />\",\" \")\n","  return tf.strings.regex_replace(stripped_html,\"[%s]\" % re.escape(\"!#$%&'()*+,-./:;<=>?@\\^_`{|}~\"),\"\")"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e8TvHxb4ZgaS","executionInfo":{"status":"ok","timestamp":1639448908112,"user_tz":480,"elapsed":26290,"user":{"displayName":"Shaobo Zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07927447856433166080"}},"outputId":"8ea884fc-4410-497f-8074-4ac7d92d2790"},"source":["def get_vectorize_layer(texts,vocab_size,max_seq,special_tokens=[\"[MASK]\"]):\n","  vectorize_layer = TextVectorization(\n","      max_tokens = vocab_size,\n","      output_mode=\"int\",\n","      standardize=custom_standardization,\n","      output_sequence_length=max_seq,\n","  )\n","  vectorize_layer.adapt(texts)\n","\n","  vocab = vectorize_layer.get_vocabulary()\n","  print(vocab[0:2])\n","  vocab = vocab[2:vocab_size-len(special_tokens)]+[\"[mask]\"]\n","  print(vocab[0:2])\n","  vectorize_layer.set_vocabulary(vocab)\n","  return vectorize_layer\n","\n","vectorize_layer = get_vectorize_layer(\n","    all_data.review.values.tolist(),\n","    config.VOCAB_SIZE,\n","    config.MAX_LEN,\n","    special_tokens=[\"[mask]\"]\n",")\n","\n","\n"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["['', '[UNK]']\n","['the', 'and']\n"]}]},{"cell_type":"code","metadata":{"id":"rt4eRdE7cN7t"},"source":["#vocab_data = [\"earth\", \"wind\", \"and\", \"fire\"]\n","#max_len = 4\n","#max_features = 5000\n","#vectorize_layer = tf.keras.layers.TextVectorization(\n","# max_tokens=max_features,\n","# output_mode='int',\n","# output_sequence_length=max_len,\n","# )\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Orfi1diWcUTW","executionInfo":{"status":"ok","timestamp":1639448913140,"user_tz":480,"elapsed":124,"user":{"displayName":"Shaobo Zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07927447856433166080"}},"outputId":"735e2d08-6944-4bc1-8c91-69ce1ad59f0f"},"source":["vectorize_layer"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<keras.layers.preprocessing.text_vectorization.TextVectorization at 0x7f3aac07ce10>"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5uRl1DMOcs0v","executionInfo":{"status":"ok","timestamp":1639448913907,"user_tz":480,"elapsed":214,"user":{"displayName":"Shaobo Zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07927447856433166080"}},"outputId":"784bb2b7-3a37-46e3-8da8-4beedeba36a4"},"source":["mask_token_id = vectorize_layer([\"[mask]\"]).numpy()[0][0]\n","print(mask_token_id)\n"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["29999\n"]}]},{"cell_type":"code","metadata":{"id":"uyebNVUwde2x","executionInfo":{"status":"ok","timestamp":1639448914952,"user_tz":480,"elapsed":127,"user":{"displayName":"Shaobo Zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07927447856433166080"}}},"source":["def encode(texts):\n","  encoded_texts=vectorize_layer(texts)\n","  return encoded_texts.numpy()\n","\n","\n","\n"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tQ5flQaJbHEK","executionInfo":{"status":"ok","timestamp":1639448917316,"user_tz":480,"elapsed":168,"user":{"displayName":"Shaobo Zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07927447856433166080"}},"outputId":"9c9d3edb-88d6-4b65-9e35-d407b5dd5e29"},"source":["config.VOCAB_SIZE"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["30000"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LWS0_kj6kUzr","executionInfo":{"status":"ok","timestamp":1639448932922,"user_tz":480,"elapsed":113,"user":{"displayName":"Shaobo Zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07927447856433166080"}},"outputId":"a84c4dfd-c14a-4e52-bbe0-8b2396103ba3"},"source":["np.random.randint(3,10,4)"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([5, 7, 6, 7])"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"Cc83iC6sm-jv","executionInfo":{"status":"ok","timestamp":1639448937310,"user_tz":480,"elapsed":2930,"user":{"displayName":"Shaobo Zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07927447856433166080"}}},"source":["def get_masked_input_and_labels(encoded_texts):\n","  inp_mask=np.random.rand(*encoded_texts.shape)<0.15\n","  inp_mask[encoded_texts <=2]=False\n","  labels=-1*np.ones(encoded_texts.shape,dtype=int)\n","  labels[inp_mask] =encoded_texts[inp_mask]\n","  encoded_texts_masked = np.copy(encoded_texts)\n","\n","  inp_mask_2mask=inp_mask & (np.random.rand(*encoded_texts.shape)<0.90)\n","  encoded_texts_masked[inp_mask_2mask]=mask_token_id\n","\n","  inp_mask_2random = inp_mask_2mask & (np.random.rand(*encoded_texts.shape)<1/9)\n","  encoded_texts_masked[inp_mask_2random]=np.random.randint(3,mask_token_id,inp_mask_2random.sum())\n","\n","  sample_weights = np.ones(labels.shape)\n","\n","  sample_weights[labels==-1] = 0\n","\n","  y_labels = np.copy(encoded_texts)\n","  return encoded_texts_masked,y_labels,sample_weights\n","\n","x_train=encode(train_df.review.values)\n","y_train=train_df.sentiment.values\n","\n","train_classifier_ds=(\n","    tf.data.Dataset.from_tensor_slices((x_train,y_train)).shuffle(1000).batch(config.BATCH_SIZE)\n",")\n","\n","x_test=encode(test_df.review.values)\n","y_test=test_df.sentiment.values\n","\n","test_classifier_ds=(\n","    tf.data.Dataset.from_tensor_slices((x_train,y_train)).shuffle(1000).batch(config.BATCH_SIZE)\n",")\n","\n","\n","\n","\n"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7NrnnsuAfI-J","executionInfo":{"status":"ok","timestamp":1639448946298,"user_tz":480,"elapsed":134,"user":{"displayName":"Shaobo Zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07927447856433166080"}},"outputId":"d32e888d-6707-4592-fc4f-d1957fb7450e"},"source":["x_train.shape"],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(25000, 256)"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"d8WyZlFcfKHt","executionInfo":{"status":"ok","timestamp":1639448950672,"user_tz":480,"elapsed":3584,"user":{"displayName":"Shaobo Zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07927447856433166080"}}},"source":["test_raw_classifier_ds=tf.data.Dataset.from_tensor_slices((test_df.review.values,y_test)).batch(config.BATCH_SIZE)\n","\n","x_all_review=encode(all_data.review.values)\n","x_masked_train,y_masked_labels,sample_weights = get_masked_input_and_labels(x_all_review)\n","\n","mlm_ds = tf.data.Dataset.from_tensor_slices((x_masked_train,y_masked_labels,sample_weights))"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"zmQgWtosgN2r","executionInfo":{"status":"ok","timestamp":1639448951673,"user_tz":480,"elapsed":121,"user":{"displayName":"Shaobo Zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07927447856433166080"}}},"source":["mlm_ds = mlm_ds.shuffle(1000).batch(config.BATCH_SIZE)"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z7iVYBPWglak","executionInfo":{"status":"ok","timestamp":1639448953158,"user_tz":480,"elapsed":125,"user":{"displayName":"Shaobo Zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07927447856433166080"}}},"source":["def bert_module(query,key,value,i):\n","  attention_output=layers.MultiHeadAttention(\n","      num_heads = config.NUM_HEAD,\n","      key_dim = config.EMBED_DIM // config.NUM_HEAD,\n","      name = \"encoder_{}/multiheadattention\".format(i),\n","  )(query,key,value)\n","\n","  attention_output = layers.Dropout(0.1,name = \"encoder_{}/att_dropout\".format(i))(attention_output)\n","\n","  attention_output = layers.LayerNormalization(\n","      epsilon = 1e-6,name=\"encoder_{}/att_layernormalization\".format(i)\n","  )(query+attention_output)\n","\n","  ffn = keras.Sequential(\n","      [\n","       layers.Dense(config.FF_DIM,activation=\"relu\"),\n","       layers.Dense(config.EMBED_DIM)\n","      ], name=\"encoder_{}/ffn\".format(i)\n","  )\n","\n","  ffn_output = ffn(attention_output)\n","  ffn_output=layers.Dropout(0.1,name=\"encoder_{}/ffn_dropout\".format(i))(ffn_output)\n","\n","  sequence_output = layers.LayerNormalization(\n","      epsilon = 1e-6,name=\"encoder_{}/ffn_layernormalization\".format(i)\n","  )(ffn_output+attention_output)\n","\n","  return sequence_output\n","\n","\n","def get_pos_encoding_matrix(max_len,d_emb):\n","  pos_enc = np.array(\n","      [\n","       [pos/np.power(10000,2*(j//2)/d_emb) for j in range(d_emb)]\n","       if pos !=0\n","       else np.zeros(d_emb)\n","       for pos in range(max_len)\n","      ]\n","  )\n","  pos_enc[1:,0::2] = np.sin(pos_enc[1:,0::2])\n","  pos_enc[1:,1::2] = np.sin(pos_enc[1:,1::2])\n","  return pos_enc\n","\n","loss_fn=keras.losses.SparseCategoricalCrossentropy(\n","    reduction = tf.keras.losses.Reduction.NONE\n",")\n","\n","loss_tracker = tf.keras.metrics.Mean(name=\"loss\")\n","\n","\n"],"execution_count":24,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"2BLNeOKsHXX-"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-vsN05anBg9G","executionInfo":{"status":"ok","timestamp":1639448956186,"user_tz":480,"elapsed":303,"user":{"displayName":"Shaobo Zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07927447856433166080"}}},"source":["class MaskedLanguageModel(tf.keras.Model):\n","  def train_step(self,inputs):\n","    if len(inputs) == 3:\n","      features,labels,sample_weight = inputs\n","    else:\n","      features,labels = inputs\n","      sample_weight = None\n","    with tf.GradientTape() as tape:\n","      predictions = self(features, training= True)\n","      loss = loss_fn(labels,predictions,sample_weight=sample_weight)\n","\n","    trainable_vars = self.trainable_variables\n","    gradients = tape.gradient(loss,trainable_vars)\n","\n","    self.optimizer.apply_gradients(zip(gradients,trainable_vars))\n","\n","    loss_tracker.update_state(loss,sample_weight=sample_weight)\n","\n","    return {\"loss\":loss_tracker.result()}\n","\n","  @property\n","  def metrics(self):\n","    return [loss_tracker]\n","\n","def create_masked_language_bert_model():\n","    inputs = layers.Input((config.MAX_LEN,), dtype=tf.int64)\n","\n","    word_embeddings = layers.Embedding(\n","        config.VOCAB_SIZE, config.EMBED_DIM, name=\"word_embedding\"\n","    )(inputs)\n","    position_embeddings = layers.Embedding(\n","        input_dim=config.MAX_LEN,\n","        output_dim=config.EMBED_DIM,\n","        weights=[get_pos_encoding_matrix(config.MAX_LEN, config.EMBED_DIM)],\n","        name=\"position_embedding\",\n","    )(tf.range(start=0, limit=config.MAX_LEN, delta=1))\n","    embeddings = word_embeddings + position_embeddings\n","\n","    encoder_output = embeddings\n","    for i in range(config.NUM_LAYERS):\n","        encoder_output = bert_module(encoder_output, encoder_output, encoder_output, i)\n","\n","    mlm_output = layers.Dense(config.VOCAB_SIZE, name=\"mlm_cls\", activation=\"softmax\")(\n","        encoder_output\n","    )\n","    mlm_model = MaskedLanguageModel(inputs, mlm_output, name=\"masked_bert_model\")\n","\n","    optimizer = keras.optimizers.Adam(learning_rate=config.LR)\n","    mlm_model.compile(optimizer=optimizer)\n","    return mlm_model\n","\n","id2token= dict(enumerate(vectorize_layer.get_vocabulary()))\n","token2id = {y: x for x,y in id2token.items()}"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WBmpY4mfS4_9","executionInfo":{"status":"ok","timestamp":1639451994576,"user_tz":480,"elapsed":467,"user":{"displayName":"Shaobo Zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07927447856433166080"}},"outputId":"d0fd7001-a73a-4413-de35-32e130ed95ac"},"source":["class MaskedTextGenerator(keras.callbacks.Callback):\n","  def __init__(self, sample_tokens, top_k=5):\n","    self.sample_tokens = sample_tokens\n","    self.k=top_k\n","\n","  def decode(self,tokens):\n","    return \" \".join([id2token[t] for t in tokens if t!=0])\n","  \n","  def convert_ids_to_tokens(self,id):\n","    return id2token[id]\n","\n","  def on_epoch_end(self,epoch,logs=None):\n","    prediction = self.model.predict(self.sample_tokens)\n","\n","    masked_index = np.where(self.sample_tokens == mask_token_id)\n","    masked_index = masked_index[1]\n","    mask_predition = prediction[0][masked_index]\n","\n","    top_indices = mask_predition[0].argsort()[-self.k :][::-1]\n","    values = mask_predition[0][top_indices]\n","\n","    for i in range(len(top_indices)):\n","      p=top_indices[i]\n","      v=values[i]\n","\n","      token = np.copy(sample_tokens[0])\n","      token[masked_index[0]]=p\n","      result = {\n","          \"inpt_text\":self.decode(sample_tokens[0].numpy()),\n","          \"predition:\": self.decode(token),\n","          \"propability:\": v,\n","          \"predicted mask token\": self.convert_ids_to_tokens(p),\n","      }\n","      pprint(result)\n","\n","sample_tokens = vectorize_layer([\"I have watched this [mask] and it was awesome\"])\n","generator_callback=MaskedTextGenerator(sample_tokens.numpy(),top_k=5)\n","\n","bert_masked_model = create_masked_language_bert_model()\n","\n","bert_masked_model.summary()"],"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"masked_bert_model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_5 (InputLayer)           [(None, 256)]        0           []                               \n","                                                                                                  \n"," word_embedding (Embedding)     (None, 256, 128)     3840000     ['input_5[0][0]']                \n","                                                                                                  \n"," tf.__operators__.add_12 (TFOpL  (None, 256, 128)    0           ['word_embedding[0][0]']         \n"," ambda)                                                                                           \n","                                                                                                  \n"," encoder_0/multiheadattention (  (None, 256, 128)    66048       ['tf.__operators__.add_12[0][0]',\n"," MultiHeadAttention)                                              'tf.__operators__.add_12[0][0]',\n","                                                                  'tf.__operators__.add_12[0][0]']\n","                                                                                                  \n"," encoder_0/att_dropout (Dropout  (None, 256, 128)    0           ['encoder_0/multiheadattention[0]\n"," )                                                               [0]']                            \n","                                                                                                  \n"," tf.__operators__.add_13 (TFOpL  (None, 256, 128)    0           ['tf.__operators__.add_12[0][0]',\n"," ambda)                                                           'encoder_0/att_dropout[0][0]']  \n","                                                                                                  \n"," encoder_0/att_layernormalizati  (None, 256, 128)    256         ['tf.__operators__.add_13[0][0]']\n"," on (LayerNormalization)                                                                          \n","                                                                                                  \n"," encoder_0/ffn (Sequential)     (None, 256, 128)     33024       ['encoder_0/att_layernormalizatio\n","                                                                 n[0][0]']                        \n","                                                                                                  \n"," encoder_0/ffn_dropout (Dropout  (None, 256, 128)    0           ['encoder_0/ffn[0][0]']          \n"," )                                                                                                \n","                                                                                                  \n"," tf.__operators__.add_14 (TFOpL  (None, 256, 128)    0           ['encoder_0/ffn_dropout[0][0]',  \n"," ambda)                                                           'encoder_0/att_layernormalizatio\n","                                                                 n[0][0]']                        \n","                                                                                                  \n"," encoder_0/ffn_layernormalizati  (None, 256, 128)    256         ['tf.__operators__.add_14[0][0]']\n"," on (LayerNormalization)                                                                          \n","                                                                                                  \n"," mlm_cls (Dense)                (None, 256, 30000)   3870000     ['encoder_0/ffn_layernormalizatio\n","                                                                 n[0][0]']                        \n","                                                                                                  \n","==================================================================================================\n","Total params: 7,809,584\n","Trainable params: 7,809,584\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"code","metadata":{"id":"1XwqbJ9AS5WC"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6PdL9VNyYF6n","executionInfo":{"status":"ok","timestamp":1638922288315,"user_tz":480,"elapsed":170,"user":{"displayName":"Shaobo Zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07927447856433166080"}},"outputId":"e3d8334e-6725-44e2-8d8e-f8b1640c1a47"},"source":["sample_tokens.numpy()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[   10,    25,   281,    11, 29999,     3,     9,    13,  1152,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0]])"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","metadata":{"id":"5Kd5t-mbYHBO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1639453909110,"user_tz":480,"elapsed":1908823,"user":{"displayName":"Shaobo Zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07927447856433166080"}},"outputId":"bae79cdf-ce36-4b29-ab8e-691059fc3bb7"},"source":["bert_masked_model.fit(mlm_ds,epochs=5,callbacks=[generator_callback])\n","bert_masked_model.save(\"bert_mlm_imbd.h5\")"],"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","1563/1563 [==============================] - ETA: 0s - loss: 6.9861WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3a2b0a4830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","{'inpt_text': 'i have watched this [mask] and it was awesome',\n"," 'predicted mask token': 'movie',\n"," 'predition:': 'i have watched this movie and it was awesome',\n"," 'propability:': 0.08023246}\n","{'inpt_text': 'i have watched this [mask] and it was awesome',\n"," 'predicted mask token': 'is',\n"," 'predition:': 'i have watched this is and it was awesome',\n"," 'propability:': 0.072441176}\n","{'inpt_text': 'i have watched this [mask] and it was awesome',\n"," 'predicted mask token': 'film',\n"," 'predition:': 'i have watched this film and it was awesome',\n"," 'propability:': 0.046516646}\n","{'inpt_text': 'i have watched this [mask] and it was awesome',\n"," 'predicted mask token': 'this',\n"," 'predition:': 'i have watched this this and it was awesome',\n"," 'propability:': 0.04371116}\n","{'inpt_text': 'i have watched this [mask] and it was awesome',\n"," 'predicted mask token': 'a',\n"," 'predition:': 'i have watched this a and it was awesome',\n"," 'propability:': 0.029370662}\n","1563/1563 [==============================] - 381s 243ms/step - loss: 6.9861\n","Epoch 2/5\n","1563/1563 [==============================] - ETA: 0s - loss: 6.2545{'inpt_text': 'i have watched this [mask] and it was awesome',\n"," 'predicted mask token': 'movie',\n"," 'predition:': 'i have watched this movie and it was awesome',\n"," 'propability:': 0.3139409}\n","{'inpt_text': 'i have watched this [mask] and it was awesome',\n"," 'predicted mask token': 'film',\n"," 'predition:': 'i have watched this film and it was awesome',\n"," 'propability:': 0.07780938}\n","{'inpt_text': 'i have watched this [mask] and it was awesome',\n"," 'predicted mask token': 'is',\n"," 'predition:': 'i have watched this is and it was awesome',\n"," 'propability:': 0.038995698}\n","{'inpt_text': 'i have watched this [mask] and it was awesome',\n"," 'predicted mask token': 'was',\n"," 'predition:': 'i have watched this was and it was awesome',\n"," 'propability:': 0.017568015}\n","{'inpt_text': 'i have watched this [mask] and it was awesome',\n"," 'predicted mask token': 'seen',\n"," 'predition:': 'i have watched this seen and it was awesome',\n"," 'propability:': 0.014116479}\n","1563/1563 [==============================] - 380s 243ms/step - loss: 6.2545\n","Epoch 3/5\n","1563/1563 [==============================] - ETA: 0s - loss: 5.7430{'inpt_text': 'i have watched this [mask] and it was awesome',\n"," 'predicted mask token': 'movie',\n"," 'predition:': 'i have watched this movie and it was awesome',\n"," 'propability:': 0.5614538}\n","{'inpt_text': 'i have watched this [mask] and it was awesome',\n"," 'predicted mask token': 'film',\n"," 'predition:': 'i have watched this film and it was awesome',\n"," 'propability:': 0.14573209}\n","{'inpt_text': 'i have watched this [mask] and it was awesome',\n"," 'predicted mask token': 'review',\n"," 'predition:': 'i have watched this review and it was awesome',\n"," 'propability:': 0.019157527}\n","{'inpt_text': 'i have watched this [mask] and it was awesome',\n"," 'predicted mask token': 'one',\n"," 'predition:': 'i have watched this one and it was awesome',\n"," 'propability:': 0.017079512}\n","{'inpt_text': 'i have watched this [mask] and it was awesome',\n"," 'predicted mask token': 'time',\n"," 'predition:': 'i have watched this time and it was awesome',\n"," 'propability:': 0.015223432}\n","1563/1563 [==============================] - 381s 244ms/step - loss: 5.7430\n","Epoch 4/5\n","1563/1563 [==============================] - ETA: 0s - loss: 5.1974{'inpt_text': 'i have watched this [mask] and it was awesome',\n"," 'predicted mask token': 'movie',\n"," 'predition:': 'i have watched this movie and it was awesome',\n"," 'propability:': 0.358177}\n","{'inpt_text': 'i have watched this [mask] and it was awesome',\n"," 'predicted mask token': 'film',\n"," 'predition:': 'i have watched this film and it was awesome',\n"," 'propability:': 0.14036705}\n","{'inpt_text': 'i have watched this [mask] and it was awesome',\n"," 'predicted mask token': 'one',\n"," 'predition:': 'i have watched this one and it was awesome',\n"," 'propability:': 0.053185336}\n","{'inpt_text': 'i have watched this [mask] and it was awesome',\n"," 'predicted mask token': 'time',\n"," 'predition:': 'i have watched this time and it was awesome',\n"," 'propability:': 0.046337467}\n","{'inpt_text': 'i have watched this [mask] and it was awesome',\n"," 'predicted mask token': 'show',\n"," 'predition:': 'i have watched this show and it was awesome',\n"," 'propability:': 0.039289307}\n","1563/1563 [==============================] - 381s 244ms/step - loss: 5.1974\n","Epoch 5/5\n","1563/1563 [==============================] - ETA: 0s - loss: 4.8096{'inpt_text': 'i have watched this [mask] and it was awesome',\n"," 'predicted mask token': 'movie',\n"," 'predition:': 'i have watched this movie and it was awesome',\n"," 'propability:': 0.49093804}\n","{'inpt_text': 'i have watched this [mask] and it was awesome',\n"," 'predicted mask token': 'film',\n"," 'predition:': 'i have watched this film and it was awesome',\n"," 'propability:': 0.08504855}\n","{'inpt_text': 'i have watched this [mask] and it was awesome',\n"," 'predicted mask token': 'show',\n"," 'predition:': 'i have watched this show and it was awesome',\n"," 'propability:': 0.036415406}\n","{'inpt_text': 'i have watched this [mask] and it was awesome',\n"," 'predicted mask token': 'review',\n"," 'predition:': 'i have watched this review and it was awesome',\n"," 'propability:': 0.036131434}\n","{'inpt_text': 'i have watched this [mask] and it was awesome',\n"," 'predicted mask token': 'one',\n"," 'predition:': 'i have watched this one and it was awesome',\n"," 'propability:': 0.035557535}\n","1563/1563 [==============================] - 381s 244ms/step - loss: 4.8096\n"]}]},{"cell_type":"code","source":["mlm_model = keras.models.load_model(\"bert_mlm_imbd.h5\",custom_objects = {\"MaskedLanguageModel\":MaskedLanguageModel})\n","pretrained_bert_model = tf.keras.Model(\n","    mlm_model.input,mlm_model.get_layer(\"encoder_0/ffn_layernormalization\").output\n",")\n","\n","pretrained_bert_model.trainable = False\n","\n","def create_classifier_bert_model():\n","  inputs = layers.Input((config.MAX_LEN,),dtype = tf.int64)\n","  sequence_output= pretrained_bert_model(inputs)\n","  pooled_output = layers.GlobalMaxPooling1D()(sequence_output)\n","  hidden_layer = layers.Dense(64,activation=\"relu\")(pooled_output)\n","  outputs=layers.Dense(1,activation = 'sigmoid')(hidden_layer)\n","  classifer_model = keras.Model(inputs,outputs,name = \"classification\")\n","\n","  optimizer = keras.optimizers.Adam()\n","  classifer_model.compile(\n","      optimizer = optimizer,loss = \"binary_crossentropy\",metrics = [\"accuracy\"]\n","  )\n","  return classifer_model\n","\n","classifer_model=create_classifier_bert_model()\n","classifer_model.summary\n","\n","classifer_model.fit(\n","    train_classifier_ds,\n","    epochs=5,\n","    validation_data=test_classifier_ds\n",")"],"metadata":{"id":"fpwIsm8ACEkH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1639454584938,"user_tz":480,"elapsed":128587,"user":{"displayName":"Shaobo Zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07927447856433166080"}},"outputId":"3e857fbe-cb53-4e1a-b7f8-7cdd18f05d84"},"execution_count":50,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","782/782 [==============================] - 24s 28ms/step - loss: 0.7101 - accuracy: 0.5762 - val_loss: 0.6998 - val_accuracy: 0.5830\n","Epoch 2/5\n","782/782 [==============================] - 21s 27ms/step - loss: 0.6461 - accuracy: 0.6331 - val_loss: 0.6165 - val_accuracy: 0.6578\n","Epoch 3/5\n","782/782 [==============================] - 21s 27ms/step - loss: 0.6319 - accuracy: 0.6446 - val_loss: 0.6138 - val_accuracy: 0.6634\n","Epoch 4/5\n","782/782 [==============================] - 21s 27ms/step - loss: 0.6256 - accuracy: 0.6500 - val_loss: 0.6063 - val_accuracy: 0.6718\n","Epoch 5/5\n","782/782 [==============================] - 21s 27ms/step - loss: 0.6258 - accuracy: 0.6517 - val_loss: 0.6044 - val_accuracy: 0.6729\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f3a2ac4ae10>"]},"metadata":{},"execution_count":50}]},{"cell_type":"code","source":["def get_end_to_end(model):\n","  inputs_string=keras.Input(shape=(1,),dtype=\"string\")\n","  indices = vectorize_layer(inputs_string)\n","  outputs = model(indices)\n","  end_to_end_model = keras.Model(inputs_string,outputs,name=\"end_to_end_model\")\n","  optimizer = keras.optimizers.Adam(learning_rate=config.LR)\n","\n","  end_to_end_model.compile(\n","      optimizer = optimizer,loss=\"binary_crossentropy\",metrics =[\"accuracy\"]\n","  )\n","  return end_to_end_model\n","\n","\n","end_to_end_classifier_model=get_end_to_end(classifer_model)\n","end_to_end_classifier_model.evaluate(test_raw_classifier_ds)\n","end_to_end_classifier_model.predict(test_raw_classifier_ds)"],"metadata":{"id":"I81mH42EMKOM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1639454667128,"user_tz":480,"elapsed":26160,"user":{"displayName":"Shaobo Zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07927447856433166080"}},"outputId":"0bfe8600-a889-421a-a80c-817dbb16e518"},"execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["782/782 [==============================] - 16s 19ms/step - loss: 0.6135 - accuracy: 0.6662\n","WARNING:tensorflow:6 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3a2afdc710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"output_type":"execute_result","data":{"text/plain":["array([[0.669455  ],\n","       [0.6705303 ],\n","       [0.40680677],\n","       ...,\n","       [0.46341455],\n","       [0.16296831],\n","       [0.76031137]], dtype=float32)"]},"metadata":{},"execution_count":52}]},{"cell_type":"code","source":[""],"metadata":{"id":"B0VVXFm5HG4w"},"execution_count":null,"outputs":[]}]}